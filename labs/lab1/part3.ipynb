{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision - Semester 8, Spring 2021\n",
    "\n",
    "## Laboratory Project 1: Points of interest detection & feature extraction in images\n",
    "     Christos Dimopoulos (031 17 037)\n",
    "     Dimitris Dimos (031 17 165)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Image Matching & Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from matplotlib import rcParams\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import cv21_lab1_part3_utils as p3\n",
    "from ipynb.fs.full.part2 import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some typical values for the following parameters\n",
    "typical = {\n",
    "    'sigma': 2,\n",
    "    'rho': 2.5,\n",
    "    'k': 0.05,\n",
    "    'theta_corn': 0.005,\n",
    "    's': 1.5,\n",
    "    'N': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Image Matching after Rotation & Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SURF Descriptor\n",
    "desc_fun1 = lambda I, kp: p3.featuresSURF(I,kp)\n",
    "\n",
    "# HOG Descriptor\n",
    "desc_fun2 = lambda I, kp: p3.featuresHOG(I,kp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A) Firstly, we evaluate matching for the Harris-Stephend Edge Detector using both SURF & HOG Methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a lambda which acts as a wrapper for detector function, e.g. harrisDetector.\n",
    "# The detector arguments are, in order: image, sigma, rho, k, threshold.\n",
    "detect_fun1 = lambda I: HarrisStephens(I, typical['sigma'],\n",
    "                                    typical['rho'],\n",
    "                                    typical['k'],\n",
    "                                    typical['theta_corn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harris Stephens Edge Detection - SURF:\n",
      "Avg. Scale Error for Image 1: 0.003\n",
      "Avg. Theta Error for Image 1: 1.968\n",
      "Avg. Scale Error for Image 2: 0.002\n",
      "Avg. Theta Error for Image 2: 0.318\n",
      "Avg. Scale Error for Image 3: 0.097\n",
      "Avg. Theta Error for Image 3: 12.909\n"
     ]
    }
   ],
   "source": [
    "# Matching Evaluation for Edge Detection using Harris-Stephens Algorithm\n",
    "\n",
    "# Execute evaluation by providing the above functions as arguments\n",
    "# Returns 2 1x3 arrays containing the errors\n",
    "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun1, desc_fun1)\n",
    "print(\"Harris Stephens Edge Detection - SURF:\")\n",
    "print('Avg. Scale Error for Image 1: {:.3f}'.format(avg_scale_errors[0]))\n",
    "print('Avg. Theta Error for Image 1: {:.3f}'.format(avg_theta_errors[0]))\n",
    "print('Avg. Scale Error for Image 2: {:.3f}'.format(avg_scale_errors[1]))\n",
    "print('Avg. Theta Error for Image 2: {:.3f}'.format(avg_theta_errors[1]))\n",
    "print('Avg. Scale Error for Image 3: {:.3f}'.format(avg_scale_errors[2]))\n",
    "print('Avg. Theta Error for Image 3: {:.3f}'.format(avg_theta_errors[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harris Stephens Edge Detection - HOG:\n",
      "Avg. Scale Error for Image 1: 0.186\n",
      "Avg. Theta Error for Image 1: 22.619\n",
      "Avg. Scale Error for Image 2: 0.351\n",
      "Avg. Theta Error for Image 2: 19.199\n",
      "Avg. Scale Error for Image 3: 0.285\n",
      "Avg. Theta Error for Image 3: 23.699\n"
     ]
    }
   ],
   "source": [
    "# Execute evaluation by providing the above functions as arguments\n",
    "# Returns 2 1x3 arrays containing the errors\n",
    "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun1, desc_fun2)\n",
    "print(\"Harris Stephens Edge Detection - HOG:\")\n",
    "print('Avg. Scale Error for Image 1: {:.3f}'.format(avg_scale_errors[0]))\n",
    "print('Avg. Theta Error for Image 1: {:.3f}'.format(avg_theta_errors[0]))\n",
    "print('Avg. Scale Error for Image 2: {:.3f}'.format(avg_scale_errors[1]))\n",
    "print('Avg. Theta Error for Image 2: {:.3f}'.format(avg_theta_errors[1]))\n",
    "print('Avg. Scale Error for Image 3: {:.3f}'.format(avg_scale_errors[2]))\n",
    "print('Avg. Theta Error for Image 3: {:.3f}'.format(avg_theta_errors[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(B) Next up, we evaluate matching with Harris-Laplace Multiscale Edge Detectors, using both SURF & HOG Methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_fun2 = lambda I: HarrisLaplacian(I,\n",
    "                                    typical['sigma'],\n",
    "                                    typical['rho'],\n",
    "                                    typical['k'],\n",
    "                                    typical['theta_corn'],\n",
    "                                    typical['s'],\n",
    "                                    typical['N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harris Laplace Multiscale Edge Detection - SURF:\n",
      "Avg. Scale Error for Image 1: 0.001\n",
      "Avg. Theta Error for Image 1: 0.077\n",
      "Avg. Scale Error for Image 2: 0.002\n",
      "Avg. Theta Error for Image 2: 0.183\n",
      "Avg. Scale Error for Image 3: 0.002\n",
      "Avg. Theta Error for Image 3: 0.144\n"
     ]
    }
   ],
   "source": [
    "# SURF Descriptor\n",
    "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun2, desc_fun1)\n",
    "print(\"Harris Laplace Multiscale Edge Detection - SURF:\")\n",
    "print('Avg. Scale Error for Image 1: {:.3f}'.format(avg_scale_errors[0]))\n",
    "print('Avg. Theta Error for Image 1: {:.3f}'.format(avg_theta_errors[0]))\n",
    "print('Avg. Scale Error for Image 2: {:.3f}'.format(avg_scale_errors[1]))\n",
    "print('Avg. Theta Error for Image 2: {:.3f}'.format(avg_theta_errors[1]))\n",
    "print('Avg. Scale Error for Image 3: {:.3f}'.format(avg_scale_errors[2]))\n",
    "print('Avg. Theta Error for Image 3: {:.3f}'.format(avg_theta_errors[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harris Laplace Multiscale Edge Detection - HOG:\n",
      "Avg. Scale Error for Image 1: 0.151\n",
      "Avg. Theta Error for Image 1: 22.059\n",
      "Avg. Scale Error for Image 2: 0.214\n",
      "Avg. Theta Error for Image 2: 9.729\n",
      "Avg. Scale Error for Image 3: 0.298\n",
      "Avg. Theta Error for Image 3: 23.137\n"
     ]
    }
   ],
   "source": [
    "# HOG Descriptor\n",
    "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun2, desc_fun2)\n",
    "print(\"Harris Laplace Multiscale Edge Detection - HOG:\")\n",
    "print('Avg. Scale Error for Image 1: {:.3f}'.format(avg_scale_errors[0]))\n",
    "print('Avg. Theta Error for Image 1: {:.3f}'.format(avg_theta_errors[0]))\n",
    "print('Avg. Scale Error for Image 2: {:.3f}'.format(avg_scale_errors[1]))\n",
    "print('Avg. Theta Error for Image 2: {:.3f}'.format(avg_theta_errors[1]))\n",
    "print('Avg. Scale Error for Image 3: {:.3f}'.format(avg_scale_errors[2]))\n",
    "print('Avg. Theta Error for Image 3: {:.3f}'.format(avg_theta_errors[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C) Following, we evaluate Matching of Blob Detector, using both SURF and HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_fun3 = lambda I: BlobDetect(I,\n",
    "              typical['sigma'],\n",
    "              typical['theta_corn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob Detection - SURF:\n",
      "Avg. Scale Error for Image 1: 0.013\n",
      "Avg. Theta Error for Image 1: 1.302\n",
      "Avg. Scale Error for Image 2: 0.002\n",
      "Avg. Theta Error for Image 2: 0.142\n",
      "Avg. Scale Error for Image 3: 0.001\n",
      "Avg. Theta Error for Image 3: 0.144\n"
     ]
    }
   ],
   "source": [
    "# SURF Descriptor\n",
    "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun3, desc_fun1)\n",
    "print(\"Blob Detection - SURF:\")\n",
    "print('Avg. Scale Error for Image 1: {:.3f}'.format(avg_scale_errors[0]))\n",
    "print('Avg. Theta Error for Image 1: {:.3f}'.format(avg_theta_errors[0]))\n",
    "print('Avg. Scale Error for Image 2: {:.3f}'.format(avg_scale_errors[1]))\n",
    "print('Avg. Theta Error for Image 2: {:.3f}'.format(avg_theta_errors[1]))\n",
    "print('Avg. Scale Error for Image 3: {:.3f}'.format(avg_scale_errors[2]))\n",
    "print('Avg. Theta Error for Image 3: {:.3f}'.format(avg_theta_errors[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blob Detection - HOG:\n",
      "Avg. Scale Error for Image 1: 0.119\n",
      "Avg. Theta Error for Image 1: 13.276\n",
      "Avg. Scale Error for Image 2: 0.121\n",
      "Avg. Theta Error for Image 2: 22.672\n",
      "Avg. Scale Error for Image 3: 0.145\n",
      "Avg. Theta Error for Image 3: 19.068\n"
     ]
    }
   ],
   "source": [
    "# HOG Descriptor\n",
    "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun3, desc_fun2)\n",
    "print(\"Blob Detection - HOG:\")\n",
    "print('Avg. Scale Error for Image 1: {:.3f}'.format(avg_scale_errors[0]))\n",
    "print('Avg. Theta Error for Image 1: {:.3f}'.format(avg_theta_errors[0]))\n",
    "print('Avg. Scale Error for Image 2: {:.3f}'.format(avg_scale_errors[1]))\n",
    "print('Avg. Theta Error for Image 2: {:.3f}'.format(avg_theta_errors[1]))\n",
    "print('Avg. Scale Error for Image 3: {:.3f}'.format(avg_scale_errors[2]))\n",
    "print('Avg. Theta Error for Image 3: {:.3f}'.format(avg_theta_errors[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(D) Following, we evaluate Matching of Multiscale Blob Detector, using both SURF and HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_fun4 = lambda I: HessianLaplacian(I,\n",
    "                            typical['sigma'],\n",
    "                            typical['theta_corn'],\n",
    "                            typical['s'],\n",
    "                            typical['N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian - Laplacian Multiscale Blob Detection - SURF:\n",
      "Avg. Scale Error for Image 1: 0.002\n",
      "Avg. Theta Error for Image 1: 0.054\n",
      "Avg. Scale Error for Image 2: 0.002\n",
      "Avg. Theta Error for Image 2: 0.079\n",
      "Avg. Scale Error for Image 3: 0.001\n",
      "Avg. Theta Error for Image 3: 0.070\n"
     ]
    }
   ],
   "source": [
    "# SURF Descriptor\n",
    "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun4, desc_fun1)\n",
    "print(\"Hessian - Laplacian Multiscale Blob Detection - SURF:\")\n",
    "print('Avg. Scale Error for Image 1: {:.3f}'.format(avg_scale_errors[0]))\n",
    "print('Avg. Theta Error for Image 1: {:.3f}'.format(avg_theta_errors[0]))\n",
    "print('Avg. Scale Error for Image 2: {:.3f}'.format(avg_scale_errors[1]))\n",
    "print('Avg. Theta Error for Image 2: {:.3f}'.format(avg_theta_errors[1]))\n",
    "print('Avg. Scale Error for Image 3: {:.3f}'.format(avg_scale_errors[2]))\n",
    "print('Avg. Theta Error for Image 3: {:.3f}'.format(avg_theta_errors[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian - Laplacian Multiscale Blob Detection - HOG:\n",
      "Avg. Scale Error for Image 1: 0.091\n",
      "Avg. Theta Error for Image 1: 10.699\n",
      "Avg. Scale Error for Image 2: 0.182\n",
      "Avg. Theta Error for Image 2: 21.689\n",
      "Avg. Scale Error for Image 3: 0.191\n",
      "Avg. Theta Error for Image 3: 18.588\n"
     ]
    }
   ],
   "source": [
    "# HOG Descriptor\n",
    "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun4, desc_fun2)\n",
    "print(\"Hessian - Laplacian Multiscale Blob Detection - HOG:\")\n",
    "print('Avg. Scale Error for Image 1: {:.3f}'.format(avg_scale_errors[0]))\n",
    "print('Avg. Theta Error for Image 1: {:.3f}'.format(avg_theta_errors[0]))\n",
    "print('Avg. Scale Error for Image 2: {:.3f}'.format(avg_scale_errors[1]))\n",
    "print('Avg. Theta Error for Image 2: {:.3f}'.format(avg_theta_errors[1]))\n",
    "print('Avg. Scale Error for Image 3: {:.3f}'.format(avg_scale_errors[2]))\n",
    "print('Avg. Theta Error for Image 3: {:.3f}'.format(avg_theta_errors[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(E) Finally, we evaluate Matching done with Multiscale Box Filter Detectors, using both SURF and HOG descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_fun5 = lambda I: multiscaleBoxFilterDetect(I,\n",
    "                                           typical['sigma'],\n",
    "                                           typical['theta_corn'],\n",
    "                                           typical['s'],\n",
    "                                           typical['N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box Filter Multiscale Blob Detection - SURF:\n",
      "Avg. Scale Error for Image 1: 0.003\n",
      "Avg. Theta Error for Image 1: 0.188\n",
      "Avg. Scale Error for Image 2: 0.034\n",
      "Avg. Theta Error for Image 2: 8.495\n",
      "Avg. Scale Error for Image 3: 0.012\n",
      "Avg. Theta Error for Image 3: 2.731\n"
     ]
    }
   ],
   "source": [
    "# SURF Descriptor\n",
    "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun5, desc_fun1)\n",
    "print(\"Box Filter Multiscale Blob Detection - SURF:\")\n",
    "print('Avg. Scale Error for Image 1: {:.3f}'.format(avg_scale_errors[0]))\n",
    "print('Avg. Theta Error for Image 1: {:.3f}'.format(avg_theta_errors[0]))\n",
    "print('Avg. Scale Error for Image 2: {:.3f}'.format(avg_scale_errors[1]))\n",
    "print('Avg. Theta Error for Image 2: {:.3f}'.format(avg_theta_errors[1]))\n",
    "print('Avg. Scale Error for Image 3: {:.3f}'.format(avg_scale_errors[2]))\n",
    "print('Avg. Theta Error for Image 3: {:.3f}'.format(avg_theta_errors[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box Filter Multiscale Blob Detection - HOG:\n",
      "Avg. Scale Error for Image 1: 0.208\n",
      "Avg. Theta Error for Image 1: 24.985\n",
      "Avg. Scale Error for Image 2: 0.239\n",
      "Avg. Theta Error for Image 2: 30.579\n",
      "Avg. Scale Error for Image 3: 0.311\n",
      "Avg. Theta Error for Image 3: 21.849\n"
     ]
    }
   ],
   "source": [
    "# HOG Descriptor\n",
    "avg_scale_errors, avg_theta_errors = p3.matching_evaluation(detect_fun5, desc_fun2)\n",
    "print(\"Box Filter Multiscale Blob Detection - HOG:\")\n",
    "print('Avg. Scale Error for Image 1: {:.3f}'.format(avg_scale_errors[0]))\n",
    "print('Avg. Theta Error for Image 1: {:.3f}'.format(avg_theta_errors[0]))\n",
    "print('Avg. Scale Error for Image 2: {:.3f}'.format(avg_scale_errors[1]))\n",
    "print('Avg. Theta Error for Image 2: {:.3f}'.format(avg_theta_errors[1]))\n",
    "print('Avg. Scale Error for Image 3: {:.3f}'.format(avg_scale_errors[2]))\n",
    "print('Avg. Theta Error for Image 3: {:.3f}'.format(avg_theta_errors[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_acc(features):\n",
    "    accs = []\n",
    "    for k in range(5):\n",
    "        # Split into a training set and a test set.\n",
    "        data_train, label_train, data_test, label_test = p3.createTrainTest(features, k)\n",
    "\n",
    "        # Perform Kmeans to find centroids for clusters.\n",
    "        BOF_tr, BOF_ts = p3.BagOfWords(data_train, data_test)\n",
    "\n",
    "        # Train an svm on the training set and make predictions on the test set\n",
    "        acc, preds, probas = p3.svm(BOF_tr, label_train, BOF_ts, label_test)\n",
    "        accs.append(acc)\n",
    "\n",
    "    return 100.0*np.mean(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(A) Firstly, we evaluate image classification with Harris-Laplace Multiscale Edge Detectors, using both SURF & HOG Methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_fun1 = lambda I: HarrisLaplacian(I,\n",
    "                                    typical['sigma'],\n",
    "                                    typical['rho'],\n",
    "                                    typical['k'],\n",
    "                                    typical['theta_corn'],\n",
    "                                    typical['s'],\n",
    "                                    typical['N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for feature extraction: 333.750\n"
     ]
    }
   ],
   "source": [
    "# SURF Method\n",
    "# Extract features from the provided dataset.\n",
    "feats1a = p3.FeatureExtraction(detect_fun1, desc_fun1, saveFile = 'HarrisLaplacian_SURF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for Harris-Laplace with SURF descriptors: 61.103%\n"
     ]
    }
   ],
   "source": [
    "acc1a = mean_acc(feats1a)\n",
    "print('Mean accuracy for Harris-Laplace with SURF descriptors: {:.3f}%'.format(acc1a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for feature extraction: 347.916\n"
     ]
    }
   ],
   "source": [
    "# HOG Method\n",
    "# Extract features from the provided dataset.\n",
    "feats1b = p3.FeatureExtraction(detect_fun1, desc_fun2, saveFile = 'HarrisLaplacian_HOG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for Harris-Laplace with HOG descriptors: 66.483%\n"
     ]
    }
   ],
   "source": [
    "acc1b = mean_acc(feats1b)\n",
    "print('Mean accuracy for Harris-Laplace with HOG descriptors: {:.3f}%'.format(acc1b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(B) Up next, we evaluate image classification with Hessian-Laplace Multiscale Blob Detectors, using both SURF & HOG Methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_fun2 = lambda I: HessianLaplacian(I,\n",
    "                            typical['sigma'],\n",
    "                            typical['theta_corn'],\n",
    "                            typical['s'],\n",
    "                            typical['N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for feature extraction: 328.251\n"
     ]
    }
   ],
   "source": [
    "# SURF Method\n",
    "# Extract features from the provided dataset.\n",
    "feats2a = p3.FeatureExtraction(detect_fun2, desc_fun1, saveFile = 'HessianLaplacian_SURF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for Hessian-Laplace with SURF descriptors: 62.207%\n"
     ]
    }
   ],
   "source": [
    "acc2a = mean_acc(feats2a)\n",
    "print('Mean accuracy for Hessian-Laplace with SURF descriptors: {:.3f}%'.format(acc2a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for feature extraction: 381.060\n"
     ]
    }
   ],
   "source": [
    "# HOG Method\n",
    "# Extract features from the provided dataset.\n",
    "feats2b = p3.FeatureExtraction(detect_fun2, desc_fun2, saveFile = 'HessianLaplacian_HOG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for Hessian-Laplace with HOG descriptors: 65.931%\n"
     ]
    }
   ],
   "source": [
    "acc2b = mean_acc(feats2b)\n",
    "print('Mean accuracy for Hessian-Laplace with HOG descriptors: {:.3f}%'.format(acc2b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C) Finally, we evaluate image classification with Box-Filter Multiscale Blob Detectors, using both SURF & HOG Methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_fun3 = lambda I: multiscaleBoxFilterDetect(I,\n",
    "                                           typical['sigma'],\n",
    "                                           typical['theta_corn'],\n",
    "                                           typical['s'],\n",
    "                                           typical['N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for feature extraction: 327.403\n"
     ]
    }
   ],
   "source": [
    "# SURF Method\n",
    "# Extract features from the provided dataset.\n",
    "feats3a = p3.FeatureExtraction(detect_fun3, desc_fun1, saveFile = 'BoxFilter_SURF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for Multiscale Box-Filters with SURF descriptors: 50.621%\n"
     ]
    }
   ],
   "source": [
    "acc3a = mean_acc(feats3a)\n",
    "print('Mean accuracy for Multiscale Box-Filters with SURF descriptors: {:.3f}%'.format(acc3a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for feature extraction: 386.113\n"
     ]
    }
   ],
   "source": [
    "# HOG Method\n",
    "# Extract features from the provided dataset.\n",
    "feats3b = p3.FeatureExtraction(detect_fun3, desc_fun2, saveFile = 'BoxFilter_HOG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for Multiscale Box-Filters with HOG descriptors: 57.793%\n"
     ]
    }
   ],
   "source": [
    "acc3b = mean_acc(feats3b)\n",
    "print('Mean accuracy for Multiscale Box-Filters with HOG descriptors: {:.3f}%'.format(acc3b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS: Create Bag of Visual Words using Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_maker(image, centroids):\n",
    "    #compute pairwise euclidean distance for each image from each centroid\n",
    "    dist = cdist(image, centroids)\n",
    "    \n",
    "    # keep as label the centroid of minimum distance\n",
    "    labels = np.zeros(dist.shape[0])\n",
    "    for i in range(labels.shape[0]):\n",
    "        labels[i] = np.argwhere(dist[i] == np.min(dist[i]))\n",
    "    \n",
    "    # Create Histogram\n",
    "    histogram, bins = np.histogram(labels, np.arange(0,centroids.shape[0]))\n",
    "    \n",
    "    # Normalize\n",
    "    norm = np.linalg.norm(histogram)\n",
    "    histogram = histogram / norm\n",
    "    \n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BonusBoVW(data_train, data_test):\n",
    "    # Define useful variables\n",
    "    num_centroids = 500;\n",
    "    subset_percent = 0.5;\n",
    "\n",
    "    data_descriptors = np.vstack(data_train) #concatenate all of them\n",
    "\n",
    "    # Get a random subset of data_descriptors.\n",
    "    subset_len = np.ceil(np.shape(data_descriptors)[0] * subset_percent)\n",
    "    i = np.random.choice(np.shape(data_descriptors)[0], int(subset_len))\n",
    "    sample = data_descriptors[i]\n",
    "\n",
    "    # Perform k-means algorithm\n",
    "    kmeans = KMeans(n_clusters=num_centroids).fit(sample)\n",
    "    idx, centroids = kmeans.labels_, kmeans.cluster_centers_ \n",
    "    \n",
    "    # Create Bag of Words for Train Test using Histograms\n",
    "    BOF_tr = []\n",
    "    for image in (data_train):\n",
    "        BOF_tr.append(histogram_maker(image, centroids).tolist())\n",
    "    BOF_tr = np.stack(BOF_tr, axis=0)\n",
    "    \n",
    "    # Repeat procedure for Test Set\n",
    "    BOF_ts = []\n",
    "    for image in (data_test):\n",
    "        BOF_ts.append(histogram_maker(image, centroids).tolist())\n",
    "    BOF_ts = np.stack(BOF_ts, axis=0)\n",
    "    \n",
    "    return BOF_tr, BOF_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bonus_acc(features):\n",
    "    accs = []\n",
    "    for k in range(5):\n",
    "        # Split into a training set and a test set.\n",
    "        data_train, label_train, data_test, label_test = p3.createTrainTest(features, k)\n",
    "\n",
    "        # Use our own Bof of Visual Words Function\n",
    "        BOF_tr, BOF_ts = BonusBoVW(data_train, data_test)\n",
    "\n",
    "        # Train an svm on the training set and make predictions on the test set\n",
    "        acc, preds, probas = p3.svm(BOF_tr, label_train, BOF_ts, label_test)\n",
    "        accs.append(acc)\n",
    "        \n",
    "    return 100.0*np.mean(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Classification with new Accuracy Metric for Different Detectors & Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for Harris-Laplace with SURF descriptors: 57.241%\n"
     ]
    }
   ],
   "source": [
    "acc1a = bonus_acc(feats1a)\n",
    "print('Mean accuracy for Harris-Laplace with SURF descriptors: {:.3f}%'.format(acc1a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for Harris-Laplace with HOG descriptors: 65.655%\n"
     ]
    }
   ],
   "source": [
    "acc1b = bonus_acc(feats1b)\n",
    "print('Mean accuracy for Harris-Laplace with HOG descriptors: {:.3f}%'.format(acc1b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for Hessian-Laplace with SURF descriptors: 61.379%\n"
     ]
    }
   ],
   "source": [
    "acc2a = bonus_acc(feats2a)\n",
    "print('Mean accuracy for Hessian-Laplace with SURF descriptors: {:.3f}%'.format(acc2a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for Hessian-Laplace with HOG descriptors: 69.379%\n"
     ]
    }
   ],
   "source": [
    "acc2b = bonus_acc(feats2b)\n",
    "print('Mean accuracy for Hessian-Laplace with HOG descriptors: {:.3f}%'.format(acc2b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for Multiscale Box-Filters with SURF descriptors: 50.069%\n"
     ]
    }
   ],
   "source": [
    "acc3a = bonus_acc(feats3a)\n",
    "print('Mean accuracy for Multiscale Box-Filters with SURF descriptors: {:.3f}%'.format(acc3a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for Multiscale Box-Filters with HOG descriptors: 61.379%\n"
     ]
    }
   ],
   "source": [
    "acc3b = bonus_acc(feats3b)\n",
    "print('Mean accuracy for Multiscale Box-Filters with HOG descriptors: {:.3f}%'.format(acc3b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
