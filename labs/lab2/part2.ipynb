{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision - Semester 8, Spring 2021\n",
    "\n",
    "## Lab Project 2: Optical Flow Estimation and Video Feature Extraction for Action Recognition\n",
    "    \n",
    "    Christos Dimopoulos (031 17 037)\n",
    "    Dimitris Dimos (031 17 165)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Spacio-Temporal Interest Points Detection and Feature Extraction in Human Action Videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from cv21_lab2_2_utils import read_video, show_detection, orientation_histogram, bag_of_words, svm_train_test\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import signal\n",
    "from scipy import ndimage as nd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typical values for our tests\n",
    "typ = {\n",
    "    'sigma': 4,\n",
    "    'tau': 1.5,\n",
    "    'k': 0.005,\n",
    "    's': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input videos\n",
    "\n",
    "walking_videos = ['./data/walking/'+f for f in listdir('./data/walking/') if isfile(join('./data/walking/', f))]\n",
    "running_videos = ['./data/running/'+f for f in listdir('./data/running/') if isfile(join('./data/running/', f))]\n",
    "boxing_videos  = ['./data/boxing/' +f for f in listdir('./data/boxing/')  if isfile(join('./data/boxing/' , f))]\n",
    "boxing_videos.remove('./data/boxing/.DS_Store')\n",
    "\n",
    "walk_video1 = read_video(walking_videos[1], 200)\n",
    "run_video1  = read_video(running_videos[1], 200)\n",
    "box_video1  = read_video(boxing_videos[1],  200) \n",
    "\n",
    "walk_video2 = read_video(walking_videos[4], 200)\n",
    "run_video2  = read_video(running_videos[4], 200)\n",
    "box_video2  = read_video(boxing_videos[4],  200) \n",
    "\n",
    "walk_video3 = read_video(walking_videos[8], 200)\n",
    "run_video3  = read_video(running_videos[8], 200)\n",
    "box_video3  = read_video(boxing_videos[8],  200) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Spatio-Temporal Points of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary functions\n",
    "\n",
    "def gaussian_1D (sigma):\n",
    "    kernelSize = int (np.ceil(3*sigma)*2 + 1)\n",
    "    G = cv2.getGaussianKernel(kernelSize, sigma)\n",
    "    return G\n",
    "\n",
    "def gaussian_2D (sigma):\n",
    "    G_1D = gaussian_1D(sigma)\n",
    "    G_2D = G_1D @ G_1D.transpose()\n",
    "    return G_2D\n",
    "\n",
    "''' Gets the importance criterion H and returns a (N,4) matrix containing points of interest '''\n",
    "def calculate_interest_points(H, N, sigma):\n",
    "    \n",
    "    N_largest = np.dstack(np.unravel_index(np.argsort(H.ravel()), (H.shape[0], H.shape[1], H.shape[2])))\n",
    "    N_largest = N_largest.reshape(N_largest.shape[1], N_largest.shape[2])\n",
    "    N_largest = N_largest[-N:]\n",
    "    \n",
    "    toReturn = np.array([np.append(pair[:2][::-1],[pair[2], sigma]) for pair in N_largest])\n",
    "        \n",
    "    return toReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.1 - Harris Detector\n",
    "\n",
    "'''\n",
    "Usage: criterion = HarrisDetector(V, sigma, tau, k, s)\n",
    "\n",
    "Description:\n",
    "    Implements Harris interest points detector and returns\n",
    "    the importance criterion for the input video\n",
    " \n",
    "Input:\n",
    "    V: input video\n",
    "    sigma: initial spatial scale\n",
    "    tau: initial temporal scale\n",
    "    k: threshold\n",
    "    s: scaling parameter\n",
    "   \n",
    "Output:\n",
    "    H: Harris importance criterion\n",
    "'''\n",
    "def HarrisDetector (V, sigma, tau, k, s):\n",
    "    \n",
    "    # convert voxels to floats\n",
    "    V = V.astype(np.float32)\n",
    "    \n",
    "    # create a spatial Gaussian kernel\n",
    "    Gspace = gaussian_2D(sigma)\n",
    "    Gspace = Gspace.reshape(Gspace.shape[0], Gspace.shape[1], 1) # !!!!\n",
    "    \n",
    "    # create a temporal Gaussian kernel\n",
    "    Gtime = gaussian_1D(tau)\n",
    "    Gtime = Gtime.reshape(1,1,Gtime.shape[0])\n",
    "    \n",
    "    # spatio-temporal filtering of the input video\n",
    "    G_spatio_temporal = nd.convolve(Gtime, Gspace)\n",
    "    L = nd.convolve(V, G_spatio_temporal)\n",
    "    \n",
    "    # derivative filters\n",
    "    dx_filter = np.array([[[-1],[0],[1]]], dtype=np.int8) # !!!!\n",
    "    dy_filter = np.array([[[-1]],[[0]],[[1]]], dtype=np.int8) # !!!!\n",
    "    dt_filter = np.array([[[-1,  0,  1]]], dtype=np.int8)\n",
    "    \n",
    "    # calculate L derivatives\n",
    "    Lx = nd.convolve(L, dx_filter)\n",
    "    Ly = nd.convolve(L, dy_filter)\n",
    "    Lt = nd.convolve(L, dt_filter)\n",
    "    \n",
    "    # calculate elements of M BEFORE convolution with g(x, y, t; s*sigma, s*tau)\n",
    "    Lxx = Lx*Lx\n",
    "    Lyy = Ly*Ly\n",
    "    Ltt = Lt*Lt\n",
    "    Lxy = Lx*Ly\n",
    "    Lxt = Lx*Lt\n",
    "    Lyt = Ly*Lt\n",
    "    \n",
    "    # calculate smoothing kernel g(x, y, t; s*sigma, s*tau)\n",
    "    g_space = gaussian_2D(s*sigma)\n",
    "    g_space = g_space.reshape(g_space.shape[0], g_space.shape[1], 1) # !!!!\n",
    "    \n",
    "    g_time = gaussian_1D(s*tau)\n",
    "    g_time = g_time.reshape(1, 1, g_time.shape[0])\n",
    "    \n",
    "    g_spatio_temporal = nd.convolve(g_time, g_space)\n",
    "    \n",
    "    # calculate M\n",
    "    Mxx = nd.convolve(Lxx, g_spatio_temporal)\n",
    "    Myy = nd.convolve(Lyy, g_spatio_temporal)\n",
    "    Mtt = nd.convolve(Ltt, g_spatio_temporal)\n",
    "    Mxy = nd.convolve(Lxy, g_spatio_temporal)\n",
    "    Mxt = nd.convolve(Lxt, g_spatio_temporal)\n",
    "    Myt = nd.convolve(Lyt, g_spatio_temporal)\n",
    "    \n",
    "    # calculate cornerness criterion\n",
    "    trace = Mxx + Myy + Mtt\n",
    "    det = (Mxx*Myy*Mtt - Mxx*Myt**2) - (Mtt*Mxy**2 - Mxy*Mxt*Myt) + (Mxy*Mxt*Myt - Myy*Mxt**2)\n",
    "    H = det - k*trace**3\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2 - Gabor Detector\n",
    "'''\n",
    "Usage: criterion = GaborDetector(V, sigma, tau, k, s)\n",
    "\n",
    "Description:\n",
    "    Implements Gabor interest points detector and returns\n",
    "    the importance criterion for the input video\n",
    " \n",
    "Input:\n",
    "    V: input video\n",
    "    sigma: initial spatial scale\n",
    "    tau: initial temporal scale\n",
    "   \n",
    "Output:\n",
    "    H: Gabor importance criterion\n",
    "'''\n",
    "\n",
    "def GaborDetector (V, sigma, tau):\n",
    "    \n",
    "    # convert voxels to floats\n",
    "    V = V.astype(np.float32)\n",
    "    \n",
    "    # spatial smoothing with gaussian kernel\n",
    "    Gspace = gaussian_2D(sigma)\n",
    "    Gspace = Gspace.reshape(Gspace.shape[0], Gspace.shape[1], 1) # !!!\n",
    "    Vs = nd.convolve(V, Gspace)\n",
    "    \n",
    "    # construct gabor filters\n",
    "    time = np.linspace(int(-2*tau), int(2*tau), int(4*tau+1), endpoint=True)\n",
    "    w = 4/tau\n",
    "    h_ev = -np.cos(2*np.pi*time*w)*np.exp((-time**2)/(2*tau**2))\n",
    "    h_ev = h_ev/np.linalg.norm(h_ev, ord=1)\n",
    "    h_od = -np.sin(2*np.pi*time*w)*np.exp((-time**2)/(2*tau**2))\n",
    "    h_od = h_od/np.linalg.norm(h_od, ord=1)\n",
    "    \n",
    "    # reshaping filters to convolve in the right dimension\n",
    "    h_ev = h_ev.reshape(1, 1, h_ev.shape[0])\n",
    "    h_od = h_od.reshape(1, 1, h_od.shape[0])\n",
    "    \n",
    "    # calculating importance criterion\n",
    "    H = (nd.convolve(Vs, h_ev))**2 + (nd.convolve(Vs, h_od))**2\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with Apple clang version 12.0.0 (clang-1200.0.32.29)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.4_1 --enable-shared --enable-pthreads --enable-version3 --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libdav1d --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from './HarrisDetection/walk/frame%d.png':\n",
      "  Duration: 00:00:08.00, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc), 432x288 [SAR 2835:2835 DAR 3:2], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mprofile High 4:4:4 Predictive, level 2.1, 4:4:4, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0m264 - core 161 r3049 55d517b - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=9 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './HarrisDetection/harris_walk.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv444p(tv, progressive), 432x288 [SAR 1:1 DAR 3:2], q=2-31, 25 fps, 12800 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  200 fps=0.0 q=-1.0 Lsize=     391kB time=00:00:07.88 bitrate= 406.6kbits/s speed=  28x    \n",
      "video:388kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.797985%\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mframe I:1     Avg QP:21.81  size: 14302\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mframe P:64    Avg QP:23.19  size:  4433\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mframe B:135   Avg QP:25.94  size:   731\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mconsecutive B-frames:  6.0%  8.0% 12.0% 74.0%\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mmb I  I16..4:  2.5% 78.8% 18.7%\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mmb P  I16..4:  5.5%  5.0%  1.2%  P16..4: 25.7% 13.3%  9.2%  0.0%  0.0%    skip:40.1%\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mmb B  I16..4:  0.0%  0.2%  0.1%  B16..8: 19.4%  1.9%  0.9%  direct: 2.5%  skip:75.0%  L0:37.5% L1:55.5% BI: 7.0%\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0m8x8 transform intra:47.3% inter:62.7%\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mcoded y,u,v intra: 27.8% 4.3% 4.8% inter: 18.0% 0.2% 0.3%\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mi16 v,h,dc,p: 71%  6% 23%  0%\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu:  6% 16% 61%  2%  3%  2%  4%  2%  4%\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 16% 22% 14%  6%  8%  8% 10%  7%  9%\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mWeighted P-Frames: Y:37.5% UV:10.9%\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mref P L0: 57.9% 22.8% 12.9%  5.3%  1.1%\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mref B L0: 78.9% 18.4%  2.7%\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mref B L1: 92.6%  7.4%\n",
      "\u001b[1;36m[libx264 @ 0x7fee45817800] \u001b[0mkb/s:396.69\n",
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with Apple clang version 12.0.0 (clang-1200.0.32.29)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.4_1 --enable-shared --enable-pthreads --enable-version3 --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libdav1d --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from './HarrisDetection/run/frame%d.png':\n",
      "  Duration: 00:00:08.00, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc), 432x288 [SAR 2835:2835 DAR 3:2], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mprofile High 4:4:4 Predictive, level 2.1, 4:4:4, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0m264 - core 161 r3049 55d517b - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=9 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './HarrisDetection/harris_run.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv444p(tv, progressive), 432x288 [SAR 1:1 DAR 3:2], q=2-31, 25 fps, 12800 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  200 fps=0.0 q=-1.0 Lsize=     505kB time=00:00:07.88 bitrate= 525.0kbits/s speed=23.8x    \n",
      "video:502kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.587179%\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mframe I:1     Avg QP:23.98  size: 10417\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mframe P:98    Avg QP:24.36  size:  4095\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mframe B:101   Avg QP:27.47  size:  1007\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mconsecutive B-frames: 22.0% 27.0% 15.0% 36.0%\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mmb I  I16..4:  2.9% 78.2% 18.9%\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mmb P  I16..4:  5.4%  7.9%  1.6%  P16..4: 28.2% 13.7%  8.2%  0.0%  0.0%    skip:35.0%\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mmb B  I16..4:  0.1%  1.2%  0.4%  B16..8: 20.1%  2.6%  1.2%  direct: 7.3%  skip:67.1%  L0:48.4% L1:43.6% BI: 8.0%\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0m8x8 transform intra:55.9% inter:65.3%\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mcoded y,u,v intra: 36.7% 4.4% 4.7% inter: 31.1% 0.3% 0.3%\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mi16 v,h,dc,p: 68%  9% 22%  0%\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu:  5% 16% 56%  2%  4%  2%  7%  2%  6%\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 15% 26% 15%  6%  8%  7% 10%  6%  8%\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mWeighted P-Frames: Y:71.4% UV:5.1%\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mref P L0: 57.0% 25.3% 10.5%  4.7%  2.5%\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mref B L0: 78.7% 16.7%  4.6%\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mref B L1: 91.3%  8.7%\n",
      "\u001b[1;36m[libx264 @ 0x7fcc03020600] \u001b[0mkb/s:513.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with Apple clang version 12.0.0 (clang-1200.0.32.29)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.4_1 --enable-shared --enable-pthreads --enable-version3 --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libdav1d --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from './HarrisDetection/box/frame%d.png':\n",
      "  Duration: 00:00:08.00, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc), 432x288 [SAR 2835:2835 DAR 3:2], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mprofile High 4:4:4 Predictive, level 2.1, 4:4:4, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0m264 - core 161 r3049 55d517b - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=9 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './HarrisDetection/harris_box.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv444p(tv, progressive), 432x288 [SAR 1:1 DAR 3:2], q=2-31, 25 fps, 12800 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  200 fps=0.0 q=-1.0 Lsize=     170kB time=00:00:07.88 bitrate= 176.6kbits/s speed=31.3x    \n",
      "video:167kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 1.890396%\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mframe I:1     Avg QP:22.44  size:  4299\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mframe P:60    Avg QP:23.29  size:  1396\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mframe B:139   Avg QP:25.40  size:   589\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mconsecutive B-frames:  4.5%  6.0%  7.5% 82.0%\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mmb I  I16..4: 14.8% 64.2% 21.0%\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mmb P  I16..4:  1.3%  2.9%  1.1%  P16..4: 28.7%  7.2%  3.4%  0.0%  0.0%    skip:55.4%\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mmb B  I16..4:  0.2%  0.7%  0.1%  B16..8: 26.3%  3.4%  0.7%  direct: 1.3%  skip:67.2%  L0:54.4% L1:42.2% BI: 3.4%\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0m8x8 transform intra:60.0% inter:81.3%\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mcoded y,u,v intra: 31.1% 6.4% 6.9% inter: 8.2% 0.2% 0.3%\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mi16 v,h,dc,p: 24% 28% 12% 37%\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 19% 10% 42%  2%  8%  8%  5%  3%  2%\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 20% 17% 24%  5%  9%  7%  8%  5%  4%\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mWeighted P-Frames: Y:30.0% UV:10.0%\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mref P L0: 42.1% 12.0% 23.2% 18.9%  3.8%\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mref B L0: 67.7% 22.6%  9.7%\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mref B L1: 89.5% 10.5%\n",
      "\u001b[1;36m[libx264 @ 0x7f8a9f80a800] \u001b[0mkb/s:170.02\n"
     ]
    }
   ],
   "source": [
    "# 2.1.3 - Experiments\n",
    "\n",
    "# Harris Detector\n",
    "\n",
    "# video 1\n",
    "walk_harris_criterion = HarrisDetector(walk_video3, 4, 1.5, 0.005, 2)\n",
    "run_harris_criterion  = HarrisDetector(run_video3,  4, 1.5, 0.005, 2)\n",
    "box_harris_criterion  = HarrisDetector(box_video3,  4, 1.5, 0.005, 2)\n",
    "\n",
    "walk_harris_points = calculate_interest_points(walk_harris_criterion, 600, 4)\n",
    "run_harris_points  = calculate_interest_points(run_harris_criterion,  600, 4)\n",
    "box_harris_points  = calculate_interest_points(box_harris_criterion,  600, 4)\n",
    "\n",
    "show_detection(walk_video3, walk_harris_points, save_path=r\"./HarrisDetection/walk\")\n",
    "show_detection(run_video3,  run_harris_points,  save_path=r\"./HarrisDetection/run\")\n",
    "show_detection(box_video3,  box_harris_points,  save_path=r\"./HarrisDetection/box\")\n",
    "\n",
    "!ffmpeg -i ./HarrisDetection/walk/frame%d.png -c:v libx264 -vf fps=25 ./HarrisDetection/harris_walk.mp4\n",
    "!ffmpeg -i ./HarrisDetection/run/frame%d.png -c:v libx264 -vf fps=25 ./HarrisDetection/harris_run.mp4\n",
    "!ffmpeg -i ./HarrisDetection/box/frame%d.png -c:v libx264 -vf fps=25 ./HarrisDetection/harris_box.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with Apple clang version 12.0.0 (clang-1200.0.32.29)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.4_1 --enable-shared --enable-pthreads --enable-version3 --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libdav1d --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from './GaborDetection/walk/frame%d.png':\n",
      "  Duration: 00:00:08.00, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc), 432x288 [SAR 2835:2835 DAR 3:2], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mprofile High 4:4:4 Predictive, level 2.1, 4:4:4, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0m264 - core 161 r3049 55d517b - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=9 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './GaborDetection/gabor_walk.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv444p(tv, progressive), 432x288 [SAR 1:1 DAR 3:2], q=2-31, 25 fps, 12800 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  200 fps=0.0 q=-1.0 Lsize=     364kB time=00:00:07.88 bitrate= 378.9kbits/s speed=25.9x    \n",
      "video:361kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.848303%\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mframe I:1     Avg QP:22.69  size: 14279\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mframe P:68    Avg QP:22.82  size:  4040\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mframe B:131   Avg QP:25.52  size:   613\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mconsecutive B-frames:  7.5% 10.0% 16.5% 66.0%\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mmb I  I16..4:  1.0% 79.8% 19.1%\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mmb P  I16..4:  6.2%  5.5%  0.6%  P16..4: 26.0% 13.4%  8.6%  0.0%  0.0%    skip:39.8%\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mmb B  I16..4:  0.0%  0.2%  0.1%  B16..8: 19.4%  1.8%  0.6%  direct: 2.5%  skip:75.4%  L0:37.7% L1:54.9% BI: 7.4%\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0m8x8 transform intra:49.6% inter:61.9%\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mcoded y,u,v intra: 21.9% 0.7% 0.7% inter: 18.4% 0.0% 0.0%\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mi16 v,h,dc,p: 69%  7% 24%  0%\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu:  5% 13% 66%  2%  2%  1%  4%  2%  4%\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 19% 25% 15%  6%  7%  7%  8%  6%  7%\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mWeighted P-Frames: Y:36.8% UV:2.9%\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mref P L0: 57.7% 24.1% 13.0%  3.8%  1.4%\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mref B L0: 77.6% 18.4%  4.1%\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mref B L1: 93.9%  6.1%\n",
      "\u001b[1;36m[libx264 @ 0x7ffc8b00ee00] \u001b[0mkb/s:369.35\n",
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with Apple clang version 12.0.0 (clang-1200.0.32.29)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.4_1 --enable-shared --enable-pthreads --enable-version3 --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libdav1d --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from './GaborDetection/run/frame%d.png':\n",
      "  Duration: 00:00:08.00, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc), 432x288 [SAR 2835:2835 DAR 3:2], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mprofile High 4:4:4 Predictive, level 2.1, 4:4:4, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0m264 - core 161 r3049 55d517b - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=9 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './GaborDetection/gabor_run.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv444p(tv, progressive), 432x288 [SAR 1:1 DAR 3:2], q=2-31, 25 fps, 12800 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  200 fps=0.0 q=-1.0 Lsize=     391kB time=00:00:07.88 bitrate= 406.5kbits/s speed=23.5x    \n",
      "video:388kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.788157%\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mframe I:1     Avg QP:22.56  size:  8094\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mframe P:73    Avg QP:24.76  size:  2723\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mframe B:126   Avg QP:25.96  size:  1506\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mconsecutive B-frames:  9.5% 13.0% 19.5% 58.0%\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mmb I  I16..4:  7.0% 79.0% 14.0%\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mmb P  I16..4:  2.3% 10.6%  1.2%  P16..4: 24.3%  9.9%  4.8%  0.0%  0.0%    skip:46.8%\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mmb B  I16..4:  0.5%  2.4%  0.1%  B16..8: 22.8%  4.4%  0.9%  direct: 9.0%  skip:59.7%  L0:50.5% L1:42.6% BI: 6.9%\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0m8x8 transform intra:76.1% inter:81.8%\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mcoded y,u,v intra: 63.9% 0.4% 0.5% inter: 25.7% 0.0% 0.0%\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mi16 v,h,dc,p: 15% 76%  2%  6%\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu:  6% 29% 30%  4%  5%  4%  9%  3%  9%\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 18% 34% 19%  4%  6%  5%  6%  3%  5%\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mWeighted P-Frames: Y:50.7% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mref P L0: 50.0% 19.2% 15.0% 10.9%  4.8%\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mref B L0: 73.9% 18.5%  7.6%\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mref B L1: 92.7%  7.3%\n",
      "\u001b[1;36m[libx264 @ 0x7fa19d009600] \u001b[0mkb/s:396.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with Apple clang version 12.0.0 (clang-1200.0.32.29)\n",
      "  configuration: --prefix=/usr/local/Cellar/ffmpeg/4.4_1 --enable-shared --enable-pthreads --enable-version3 --enable-avresample --cc=clang --host-cflags= --host-ldflags= --enable-ffplay --enable-gnutls --enable-gpl --enable-libaom --enable-libbluray --enable-libdav1d --enable-libmp3lame --enable-libopus --enable-librav1e --enable-librubberband --enable-libsnappy --enable-libsrt --enable-libtesseract --enable-libtheora --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxml2 --enable-libxvid --enable-lzma --enable-libfontconfig --enable-libfreetype --enable-frei0r --enable-libass --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-libspeex --enable-libsoxr --enable-libzmq --enable-libzimg --disable-libjack --disable-indev=jack --enable-videotoolbox\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libavresample   4.  0.  0 /  4.  0.  0\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from './GaborDetection/box/frame%d.png':\n",
      "  Duration: 00:00:08.00, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc), 432x288 [SAR 2835:2835 DAR 3:2], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mprofile High 4:4:4 Predictive, level 2.1, 4:4:4, 8-bit\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0m264 - core 161 r3049 55d517b - H.264/MPEG-4 AVC codec - Copyleft 2003-2021 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=9 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to './GaborDetection/gabor_box.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf58.76.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv444p(tv, progressive), 432x288 [SAR 1:1 DAR 3:2], q=2-31, 25 fps, 12800 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  200 fps=0.0 q=-1.0 Lsize=     134kB time=00:00:07.88 bitrate= 139.1kbits/s speed=26.6x    \n",
      "video:131kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.423441%\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mframe I:1     Avg QP:21.66  size:  3830\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mframe P:56    Avg QP:23.03  size:  1088\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mframe B:143   Avg QP:24.34  size:   478\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mconsecutive B-frames:  2.5%  5.0%  4.5% 88.0%\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mmb I  I16..4: 21.8% 57.4% 20.8%\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mmb P  I16..4:  2.6%  3.7%  0.8%  P16..4: 26.6%  7.1%  2.9%  0.0%  0.0%    skip:56.3%\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mmb B  I16..4:  0.4%  0.8%  0.1%  B16..8: 26.4%  3.3%  0.4%  direct: 0.5%  skip:68.1%  L0:50.3% L1:46.5% BI: 3.3%\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0m8x8 transform intra:55.9% inter:88.0%\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mcoded y,u,v intra: 27.1% 1.0% 1.0% inter: 7.8% 0.0% 0.0%\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mi16 v,h,dc,p: 20% 27%  3% 50%\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 18% 13% 40%  5%  5%  6%  4%  5%  4%\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 29% 21% 26%  4%  6%  4%  4%  4%  2%\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mWeighted P-Frames: Y:30.4% UV:3.6%\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mref P L0: 46.7%  9.7% 24.1% 15.1%  4.3%\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mref B L0: 64.8% 25.9%  9.3%\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mref B L1: 84.1% 15.9%\n",
      "\u001b[1;36m[libx264 @ 0x7f97e8819600] \u001b[0mkb/s:133.13\n"
     ]
    }
   ],
   "source": [
    "# Gabor Detector\n",
    "\n",
    "# video 1\n",
    "walk_gabor_criterion = GaborDetector(walk_video3, 1.6, 1.5)\n",
    "run_gabor_criterion  = GaborDetector(run_video2,  1.6, 1.5)\n",
    "box_gabor_criterion  = GaborDetector(box_video1,  1.6, 1.5)\n",
    "\n",
    "walk_gabor_points = calculate_interest_points(walk_gabor_criterion, 600, 1.6)\n",
    "run_gabor_points  = calculate_interest_points(run_gabor_criterion,  600, 1.6)\n",
    "box_gabor_points  = calculate_interest_points(box_gabor_criterion,  600, 1.6)\n",
    "\n",
    "show_detection(walk_video3, walk_gabor_points, save_path=r\"./GaborDetection/walk\")\n",
    "show_detection(run_video2,  run_gabor_points,  save_path=r\"./GaborDetection/run\")\n",
    "show_detection(box_video1,  box_gabor_points,  save_path=r\"./GaborDetection/box\")\n",
    "\n",
    "!ffmpeg -i ./GaborDetection/walk/frame%d.png -c:v libx264 -vf fps=25 ./GaborDetection/gabor_walk.mp4\n",
    "!ffmpeg -i ./GaborDetection/run/frame%d.png -c:v libx264 -vf fps=25 ./GaborDetection/gabor_run.mp4\n",
    "!ffmpeg -i ./GaborDetection/box/frame%d.png -c:v libx264 -vf fps=25 ./GaborDetection/gabor_box.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Spatio-Temporal Histographic Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.1 - Calculating Gradient and Optical Flow\n",
    "\n",
    "def get_gradient(V):\n",
    "    dy, dx, _ = np.gradient(V)\n",
    "    return (dy,dx)\n",
    "\n",
    "def get_optical_flow(V):\n",
    "    \n",
    "    V = V.astype(np.uint8)\n",
    "    \n",
    "    flow_x = np.zeros((V.shape[0], V.shape[1], V.shape[2]))\n",
    "    flow_y = np.zeros((V.shape[0], V.shape[1], V.shape[2]))\n",
    "    for f in range(V.shape[2]):\n",
    "        t = f\n",
    "        if f == V.shape[2]-1:\n",
    "            t = f-1\n",
    "                \n",
    "        temp = cv2.optflow.DualTVL1OpticalFlow_create(nscales=1).calc(V[:,:,t], V[:,:,t+1], None)\n",
    "        flow_x[:,:,t] = temp[:,:,1]\n",
    "        flow_y[:,:,t] = temp[:,:,0]\n",
    "        \n",
    "    print(u'\\u2713', end='')\n",
    "    return (flow_y,flow_x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.2 - HOG and HOF descriptors\n",
    "\n",
    "def get_descriptor (V, points, descriptor, nbins=9, n=3, m=3):\n",
    "    \n",
    "    height = V.shape[0]\n",
    "    width  = V.shape[1]\n",
    "    desc = []\n",
    "    \n",
    "    if descriptor == 'HOG':\n",
    "        dy, dx = get_gradient(V)\n",
    "    elif descriptor == 'HOF':\n",
    "        dy, dx = get_optical_flow(V)\n",
    "    elif descriptor == 'HOG/HOF':\n",
    "        HOG = get_descriptor(V, points, 'HOG', nbins, n, m)\n",
    "        HOF = get_descriptor(V, points, 'HOF', nbins, n, m)\n",
    "        return np.concatenate((HOG, HOF))\n",
    "    else:\n",
    "        print('Invalid Descriptor Type')\n",
    "        return\n",
    "    \n",
    "    for point in points:\n",
    "        x = point[0]\n",
    "        y = point[1]\n",
    "        t = point[2]\n",
    "        sigma = point[3]\n",
    "        side = int (np.round(4*sigma))\n",
    "        \n",
    "        x_left  = max(0, x-side)\n",
    "        x_right = min(width, x+side+1)\n",
    "        y_top   = max(0, y-side)\n",
    "        y_bot   = min(height, y+side+1) \n",
    "        \n",
    "        Gx = dx[y_top:y_bot, x_left:x_right, t]\n",
    "        Gy = dy[y_top:y_bot, x_left:x_right, t]\n",
    "        \n",
    "        desc.append( orientation_histogram(Gx, Gy, nbins, np.array([n,m])) )\n",
    "    \n",
    "    return np.array(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Bag of Visual Words Construction and use of Support Vector Machines for action classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.1 - Dividing data in train and test set\n",
    "\n",
    "def divide_into_train_test(training_videos_file):\n",
    "\n",
    "    temp_file = open('./data/'+training_videos_file, 'r')\n",
    "    lines = temp_file.readlines()\n",
    "    train_names = [i.strip() for i in lines]\n",
    "\n",
    "    train_set_temp = []\n",
    "    test_set_temp = []\n",
    "\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "\n",
    "    for name in listdir('./data/walking/'):\n",
    "        if name in train_names:\n",
    "            train_set_temp.append(read_video('./data/walking/'+name, 200))\n",
    "            train_labels.append(2)\n",
    "        else:\n",
    "            test_set_temp.append(read_video('./data/walking/'+name, 200))\n",
    "            test_labels.append(2)\n",
    "\n",
    "    for name in listdir('./data/running/'):\n",
    "        if name in train_names:\n",
    "            train_set_temp.append(read_video('./data/running/'+name, 200))\n",
    "            train_labels.append(0)\n",
    "        else:\n",
    "            test_set_temp.append(read_video('./data/running/'+name, 200))\n",
    "            test_labels.append(0)\n",
    "\n",
    "    for name in listdir('./data/boxing/'):\n",
    "        if name in train_names:\n",
    "            train_set_temp.append(read_video('./data/boxing/'+name, 200))\n",
    "            train_labels.append(1)\n",
    "        elif name != '.DS_Store':\n",
    "            test_set_temp.append(read_video('./data/boxing/'+name, 200))\n",
    "            test_labels.append(1)\n",
    "\n",
    "    train_set = np.array(train_set_temp)\n",
    "    test_set = np.array(test_set_temp)\n",
    "    \n",
    "    return train_set, test_set, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.2 - Creating Bag of Visual Words Representation\n",
    "\n",
    "def calculate_descriptor_for_video_set(descriptor, detector, video_set, sigma, tau, k, s):\n",
    "    \n",
    "    n = int(np.round(4*sigma))\n",
    "    m = int(np.round(4*sigma))\n",
    "    nbins = 9\n",
    "    \n",
    "    if descriptor != 'HOG' and descriptor != 'HOF' and descriptor != 'HOG/HOF':\n",
    "        print('Invalid Descriptor')\n",
    "        return\n",
    "    \n",
    "    descriptors_for_video_set = []\n",
    "    \n",
    "    if detector == 'Harris':\n",
    "        for video in video_set:\n",
    "            criterion = HarrisDetector(video, sigma, tau, k, s)\n",
    "            points = calculate_interest_points(criterion, 600, sigma)\n",
    "            desc = get_descriptor(video, points, descriptor, nbins, n, m)\n",
    "            descriptors_for_video_set.append(desc)\n",
    "            \n",
    "    elif detector == 'Gabor':\n",
    "        for video in video_set:\n",
    "            criterion = GaborDetector(video, sigma, tau)\n",
    "            points = calculate_interest_points(criterion, 600, sigma)\n",
    "            desc = get_descriptor(video, points, descriptor, nbins, n, m)\n",
    "            descriptors_for_video_set.append(desc)\n",
    "            \n",
    "    else:\n",
    "        print('Invalid Detector')\n",
    "        return\n",
    "    \n",
    "    return descriptors_for_video_set\n",
    "\n",
    "\n",
    "def calculate_BoVW(train_set, test_set, descriptor, detector, sigma, tau, k, s, num_centers):\n",
    "    \n",
    "    desc_train = calculate_descriptor_for_video_set(descriptor, detector, train_set, sigma, tau, k, s)\n",
    "    desc_test  = calculate_descriptor_for_video_set(descriptor, detector, test_set,  sigma, tau, k, s)\n",
    "    \n",
    "    bow_train, bow_test = bag_of_words(desc_train, desc_test, num_centers)\n",
    "    \n",
    "    return (bow_train, bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3.3 - Classification using Support Vector Machine\n",
    "\n",
    "def classify (train_set, test_set, train_labels, test_labels, descriptor, detector, sigma, tau, k, s, num_centers=20):\n",
    "    \n",
    "    print(\"Performing Classification using the following parameters:\")\n",
    "    print(\"Detector: {},\".format(detector), end=' ')\n",
    "    print(\"Descriptor: {},\".format(descriptor), end=' ')\n",
    "    print(\"sigma = {0:.2f}, tau = {1:.2f}\".format(sigma, tau))\n",
    "    print()\n",
    "    \n",
    "    bow_train, bow_test = calculate_BoVW(train_set, test_set, descriptor, detector, sigma, tau, k, s, num_centers)\n",
    "    accuracy, pred = svm_train_test(bow_train, train_labels, bow_test, test_labels)\n",
    "    \n",
    "    print(\"\\nClassification finished. The results are:\")\n",
    "    print(\"\\t Accuracy = {0:.2f}%\".format(accuracy*100))\n",
    "    print(\"\\t Pred = \", end=\"\")\n",
    "    print(pred)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Classification 1\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Harris, Descriptor: HOG, sigma = 4.00, tau = 1.50\n",
      "\n",
      "\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 91.67%\n",
      "\t Pred = [2 2 2 2 0 1 0 0 1 1 1 1]\n",
      "\n",
      "----------------\n",
      "Classification 2\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Gabor, Descriptor: HOG, sigma = 4.00, tau = 1.50\n",
      "\n",
      "\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 91.67%\n",
      "\t Pred = [2 2 2 2 0 1 0 0 1 1 1 1]\n",
      "\n",
      "----------------\n",
      "Classification 3\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Harris, Descriptor: HOF, sigma = 4.00, tau = 1.50\n",
      "\n",
      "✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 83.33%\n",
      "\t Pred = [2 0 2 2 0 0 1 0 1 1 1 1]\n",
      "\n",
      "----------------\n",
      "Classification 4\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Gabor, Descriptor: HOF, sigma = 4.00, tau = 1.50\n",
      "\n",
      "✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 83.33%\n",
      "\t Pred = [0 2 2 2 0 2 0 0 1 1 1 1]\n",
      "\n",
      "----------------\n",
      "Classification 5\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Harris, Descriptor: HOG/HOF, sigma = 4.00, tau = 1.50\n",
      "\n",
      "✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 91.67%\n",
      "\t Pred = [2 2 2 2 0 2 0 0 1 1 1 1]\n",
      "\n",
      "----------------\n",
      "Classification 6\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Gabor, Descriptor: HOG/HOF, sigma = 4.00, tau = 1.50\n",
      "\n",
      "✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 91.67%\n",
      "\t Pred = [2 2 2 2 0 2 0 0 1 1 1 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.3.4 - Experiments with different detector-descriptor combinations\n",
    "\n",
    "train_set, test_set, train_labels, test_labels = divide_into_train_test('training_videos.txt')\n",
    "sigma = typ['sigma']\n",
    "tau = typ['tau']\n",
    "k = typ['k']\n",
    "s = typ['s']\n",
    "num_centers = 20\n",
    "\n",
    "# Detector: Harris,  Descriptor: HOG\n",
    "print('----------------\\nClassification 1\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG', 'Harris', sigma, tau, k, s, 20)\n",
    "print()\n",
    "\n",
    "# Detector: Gabor,   Descriptor: HOG\n",
    "print('----------------\\nClassification 2\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG', 'Gabor', sigma, tau, k, s, 20)\n",
    "print()\n",
    "\n",
    "# Detector: Harris,  Descriptor: HOF\n",
    "print('----------------\\nClassification 3\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOF', 'Harris', sigma, tau, k, s, 20)\n",
    "print()\n",
    "\n",
    "# Detector: Gabor,   Descriptor: HOF\n",
    "print('----------------\\nClassification 4\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOF', 'Gabor', sigma, tau, k, s, 20)\n",
    "print()\n",
    "\n",
    "# Detector: Harris,  Descriptor: HOG/HOF\n",
    "print('----------------\\nClassification 5\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG/HOF', 'Harris', sigma, tau, k, s, 20)\n",
    "print()\n",
    "\n",
    "# Detector: Gabor,   Descriptor: HOG/HOF\n",
    "print('----------------\\nClassification 6\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG/HOF', 'Gabor', sigma, tau, k, s, 20)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Classification 1\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Harris, Descriptor: HOG, sigma = 4.00, tau = 1.50\n",
      "\n",
      "\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 91.67%\n",
      "\t Pred = [2 2 2 2 0 1 0 0 1 1 1 1]\n",
      "\n",
      "----------------\n",
      "Classification 2\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Gabor, Descriptor: HOG, sigma = 4.00, tau = 1.50\n",
      "\n",
      "\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 100.00%\n",
      "\t Pred = [2 2 2 2 0 0 0 0 1 1 1 1]\n",
      "\n",
      "----------------\n",
      "Classification 3\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Harris, Descriptor: HOF, sigma = 4.00, tau = 1.50\n",
      "\n",
      "✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 91.67%\n",
      "\t Pred = [2 2 2 2 0 0 1 0 1 1 1 1]\n",
      "\n",
      "----------------\n",
      "Classification 4\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Gabor, Descriptor: HOF, sigma = 4.00, tau = 1.50\n",
      "\n",
      "✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 58.33%\n",
      "\t Pred = [0 0 0 2 0 1 1 0 1 1 1 1]\n",
      "\n",
      "----------------\n",
      "Classification 5\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Harris, Descriptor: HOG/HOF, sigma = 4.00, tau = 1.50\n",
      "\n",
      "✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 91.67%\n",
      "\t Pred = [2 2 0 2 0 0 0 0 1 1 1 1]\n",
      "\n",
      "----------------\n",
      "Classification 6\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Gabor, Descriptor: HOG/HOF, sigma = 4.00, tau = 1.50\n",
      "\n",
      "✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 91.67%\n",
      "\t Pred = [2 2 2 2 0 2 0 0 1 1 1 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-running the same experiments to observe the randomness\n",
    "\n",
    "train_set, test_set, train_labels, test_labels = divide_into_train_test('training_videos.txt')\n",
    "sigma = typ['sigma']\n",
    "tau = typ['tau']\n",
    "k = typ['k']\n",
    "s = typ['s']\n",
    "num_centers = 20\n",
    "\n",
    "# Detector: Harris,  Descriptor: HOG\n",
    "print('----------------\\nClassification 1\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG', 'Harris', sigma, tau, k, s, 20)\n",
    "print()\n",
    "\n",
    "# Detector: Gabor,   Descriptor: HOG\n",
    "print('----------------\\nClassification 2\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG', 'Gabor', sigma, tau, k, s, 20)\n",
    "print()\n",
    "\n",
    "# Detector: Harris,  Descriptor: HOF\n",
    "print('----------------\\nClassification 3\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOF', 'Harris', sigma, tau, k, s, 20)\n",
    "print()\n",
    "\n",
    "# Detector: Gabor,   Descriptor: HOF\n",
    "print('----------------\\nClassification 4\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOF', 'Gabor', sigma, tau, k, s, 20)\n",
    "print()\n",
    "\n",
    "# Detector: Harris,  Descriptor: HOG/HOF\n",
    "print('----------------\\nClassification 5\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG/HOF', 'Harris', sigma, tau, k, s, 20)\n",
    "print()\n",
    "\n",
    "# Detector: Gabor,   Descriptor: HOG/HOF\n",
    "print('----------------\\nClassification 6\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG/HOF', 'Gabor', sigma, tau, k, s, 20)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Classification 2\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Gabor, Descriptor: HOG, sigma = 4.00, tau = 1.50\n",
      "\n",
      "\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 87.88%\n",
      "\t Pred = [2 2 2 2 2 2 2 2 2 2 2 0 2 0 0 1 0 0 0 2 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "----------------\n",
      "Classification 5\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Harris, Descriptor: HOG/HOF, sigma = 4.00, tau = 1.50\n",
      "\n",
      "✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 78.79%\n",
      "\t Pred = [0 2 2 0 2 0 2 0 2 0 2 2 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1]\n",
      "\n",
      "----------------\n",
      "Classification 6\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Gabor, Descriptor: HOG/HOF, sigma = 4.00, tau = 1.50\n",
      "\n",
      "✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 87.88%\n",
      "\t Pred = [2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 1 0 0 0 0 0 1 0 2 1 1 1 1 1 1 1 1 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2.3.5 - Experiments with different data partitions\n",
    "\n",
    "# Very little data\n",
    "\n",
    "train_set, test_set, train_labels, test_labels = divide_into_train_test('little_train.txt')\n",
    "sigma = typ['sigma']\n",
    "tau = typ['tau']\n",
    "k = typ['k']\n",
    "s = typ['s']\n",
    "num_centers = 20\n",
    "\n",
    "# Detector: Gabor,   Descriptor: HOG\n",
    "print('----------------\\nClassification 2\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG', 'Gabor', sigma, tau, k, s, 20)\n",
    "print()\n",
    "\n",
    "# Detector: Harris,  Descriptor: HOG/HOF\n",
    "print('----------------\\nClassification 5\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG/HOF', 'Harris', sigma, tau, k, s, 20)\n",
    "print()\n",
    "\n",
    "# Detector: Gabor,   Descriptor: HOG/HOF\n",
    "print('----------------\\nClassification 6\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG/HOF', 'Gabor', sigma, tau, k, s, 20)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Classification 2\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Gabor, Descriptor: HOG, sigma = 4.00, tau = 1.50\n",
      "\n",
      "\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 100.00%\n",
      "\t Pred = [2 2 0 0 1 1]\n",
      "\n",
      "----------------\n",
      "Classification 5\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Harris, Descriptor: HOG/HOF, sigma = 4.00, tau = 1.50\n",
      "\n",
      "✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 66.67%\n",
      "\t Pred = [2 2 2 0 1 0]\n",
      "\n",
      "----------------\n",
      "Classification 6\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Gabor, Descriptor: HOG/HOF, sigma = 4.00, tau = 1.50\n",
      "\n",
      "✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 100.00%\n",
      "\t Pred = [2 2 0 0 1 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# too big training set, very small test set\n",
    "\n",
    "train_set, test_set, train_labels, test_labels = divide_into_train_test('big_train.txt')\n",
    "sigma = typ['sigma']\n",
    "tau = typ['tau']\n",
    "k = typ['k']\n",
    "s = typ['s']\n",
    "num_centers = 20\n",
    "\n",
    "# Detector: Gabor,   Descriptor: HOG\n",
    "print('----------------\\nClassification 2\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG', 'Gabor', sigma, tau, k, s, 20)\n",
    "print()\n",
    "\n",
    "# Detector: Harris,  Descriptor: HOG/HOF\n",
    "print('----------------\\nClassification 5\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG/HOF', 'Harris', sigma, tau, k, s, 20)\n",
    "print()\n",
    "\n",
    "# Detector: Gabor,   Descriptor: HOG/HOF\n",
    "print('----------------\\nClassification 6\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG/HOF', 'Gabor', sigma, tau, k, s, 20)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Classification 2\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Gabor, Descriptor: HOG, sigma = 4.00, tau = 1.50\n",
      "\n",
      "\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 50.00%\n",
      "\t Pred = [2 2 2 2 0 0 1 1 1 2 0 0 1 0 0 0 1 0]\n",
      "\n",
      "----------------\n",
      "Classification 5\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Harris, Descriptor: HOG/HOF, sigma = 4.00, tau = 1.50\n",
      "\n",
      "✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 72.22%\n",
      "\t Pred = [2 2 0 2 1 1 2 1 0 0 1 1 1 1 1 2 1 1]\n",
      "\n",
      "----------------\n",
      "Classification 6\n",
      "----------------\n",
      "Performing Classification using the following parameters:\n",
      "Detector: Gabor, Descriptor: HOG/HOF, sigma = 4.00, tau = 1.50\n",
      "\n",
      "✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓✓\n",
      "Classification finished. The results are:\n",
      "\t Accuracy = 50.00%\n",
      "\t Pred = [0 2 2 2 0 0 0 1 0 1 0 1 1 0 1 0 0 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sufficient train data, but not many box videos\n",
    "\n",
    "train_set, test_set, train_labels, test_labels = divide_into_train_test('little_box.txt')\n",
    "sigma = typ['sigma']\n",
    "tau = typ['tau']\n",
    "k = typ['k']\n",
    "s = typ['s']\n",
    "num_centers = 20\n",
    "\n",
    "# Detector: Gabor,   Descriptor: HOG\n",
    "print('----------------\\nClassification 2\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG', 'Gabor', sigma, tau, k, s, 20)\n",
    "print()\n",
    "\n",
    "# Detector: Harris,  Descriptor: HOG/HOF\n",
    "print('----------------\\nClassification 5\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG/HOF', 'Harris', sigma, tau, k, s, 20)\n",
    "print()\n",
    "\n",
    "# Detector: Gabor,   Descriptor: HOG/HOF\n",
    "print('----------------\\nClassification 6\\n----------------')\n",
    "classify(train_set, test_set, train_labels, test_labels, 'HOG/HOF', 'Gabor', sigma, tau, k, s, 20)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
